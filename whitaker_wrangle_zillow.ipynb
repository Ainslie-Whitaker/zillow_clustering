{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c84ce6",
   "metadata": {},
   "source": [
    "# Zillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35273f",
   "metadata": {},
   "source": [
    "### Wrangling the Zillow data\n",
    "\n",
    "#### Aquuires and prepares Zillow data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc8442",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169933ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# default pandas decimal number display format\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Stats\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#My Files\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa7826",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1827bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_url(database):\n",
    "    from env import host, user, password\n",
    "    url = f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "    return url\n",
    "\n",
    "# acquire zillow data using the query\n",
    "def get_zillow():\n",
    "    # SQL Query\n",
    "    sql = '''\n",
    "\n",
    "    SELECT prop.*, \n",
    "           pred.logerror, \n",
    "           pred.transactiondate, \n",
    "           air.airconditioningdesc, \n",
    "           arch.architecturalstyledesc, \n",
    "           build.buildingclassdesc, \n",
    "           heat.heatingorsystemdesc, \n",
    "           landuse.propertylandusedesc, \n",
    "           story.storydesc, \n",
    "           construct.typeconstructiondesc \n",
    "    FROM   properties_2017 prop  \n",
    "           INNER JOIN (SELECT parcelid,\n",
    "                       Max(transactiondate) transactiondate \n",
    "                       FROM   predictions_2017 \n",
    "  \n",
    "                       GROUP  BY parcelid) pred \n",
    "                   USING (parcelid)\n",
    "                   \n",
    "                            JOIN predictions_2017 as pred USING (parcelid, transactiondate)\n",
    "           LEFT JOIN airconditioningtype air USING (airconditioningtypeid) \n",
    "           LEFT JOIN architecturalstyletype arch USING (architecturalstyletypeid) \n",
    "           LEFT JOIN buildingclasstype build USING (buildingclasstypeid) \n",
    "           LEFT JOIN heatingorsystemtype heat USING (heatingorsystemtypeid) \n",
    "           LEFT JOIN propertylandusetype landuse USING (propertylandusetypeid) \n",
    "           LEFT JOIN storytype story USING (storytypeid) \n",
    "           LEFT JOIN typeconstructiontype construct USING (typeconstructiontypeid) \n",
    "    WHERE  prop.latitude IS NOT NULL \n",
    "           AND prop.longitude IS NOT NULL\n",
    "           AND pred.id IN (SELECT MAX(id)\n",
    "           FROM predictions_2017\n",
    "           GROUP BY parcelid\n",
    "           HAVING MAX(transactiondate));\n",
    "       \n",
    "       \n",
    "'''\n",
    "    url = get_db_url('zillow')\n",
    "    df = pd.read_sql(sql, url, index_col='id')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2280f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ab2b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb18683",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456581e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to drop missing values based on a threshold\n",
    "def handle_missing_values(df, prop_required_row = 0.5, prop_required_col = 0.5):\n",
    "    ''' function which takes in a dataframe, required notnull proportions of non-null rows and columns.\n",
    "    drop the columns and rows columns based on theshold:'''\n",
    "    \n",
    "    #drop columns with nulls\n",
    "    threshold = int(prop_required_col * len(df.index)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 1, thresh = threshold, inplace = True)\n",
    "    \n",
    "    #drop rows with nulls\n",
    "    threshold = int(prop_required_row * len(df.columns)) # Require that many non-NA values.\n",
    "    df.dropna(axis = 0, thresh = threshold, inplace = True)\n",
    "    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93864568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_zillow():\n",
    "    # read saved .csv\n",
    "    df = pd.read_csv('zillow.csv')\n",
    "    \n",
    "    # propertylandusetypeid that can be considered \"single unit\" to df\n",
    "    single_unit = [261, 262, 263, 264, 268, 273, 275, 276, 279]\n",
    "    df = df[df.propertylandusetypeid.isin(single_unit)]\n",
    "    \n",
    "    # df with bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet > 0\n",
    "    df = df[(df.bedroomcnt > 0) & (df.bathroomcnt > 0) & (df.calculatedfinishedsquarefeet>0)]\n",
    "\n",
    "    \n",
    "    # drop missing values based on a threshold\n",
    "    df = handle_missing_values(df)\n",
    "   \n",
    "    # drop unnecessary columns\n",
    "    df = df.drop(columns=['id','calculatedbathnbr', 'finishedsquarefeet12', 'fullbathcnt', 'heatingorsystemtypeid', 'propertyzoningdesc', 'censustractandblock','propertycountylandusecode', 'propertylandusetypeid', 'propertylandusedesc', 'unitcnt','heatingorsystemdesc'])\n",
    "    \n",
    "    # drop null rows for specific columns only\n",
    "    df = df[df.regionidzip.notnull()]\n",
    "    df = df[df.yearbuilt.notnull()]\n",
    "    df = df[df.structuretaxvaluedollarcnt.notnull()]\n",
    "    df = df[df.taxvaluedollarcnt.notnull()]\n",
    "    df = df[df.landtaxvaluedollarcnt.notnull()]\n",
    "    df = df[df.taxamount.notnull()]\n",
    "\n",
    "    # fill NaNs with mode\n",
    "    df.buildingqualitytypeid.mode()[0]\n",
    "    df['buildingqualitytypeid'] = df.buildingqualitytypeid.fillna(df.buildingqualitytypeid.mode()[0])\n",
    "    df.lotsizesquarefeet.mode()[0]\n",
    "    df['lotsizesquarefeet'] = df.lotsizesquarefeet.fillna(df.lotsizesquarefeet.mode()[0])\n",
    "    df.regionidcity.mode()[0]\n",
    "    df['regionidcity'] = df.regionidcity.fillna(df.regionidcity.mode()[0])\n",
    "\n",
    "    \n",
    "    # crete column called county that lists column type based on fips\n",
    "    df['county'] = df['fips'].apply(\n",
    "    lambda x: 'Los Angeles' if x == 6037\\\n",
    "    else 'Orange' if x == 6059\\\n",
    "    else 'Ventura')\n",
    "    \n",
    "    # check for outliers\n",
    "    df = df[df.taxvaluedollarcnt < 5_000_000]\n",
    "    df[df.calculatedfinishedsquarefeet < 8000]\n",
    "    \n",
    "    \n",
    "    # drop nulls to make sure none were missed\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c1d76ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = wrangle_zillow()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da998b8",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c59281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    # train/validate/test split\n",
    "    # splits the data for modeling and exploring, to prevent overfitting\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "    \n",
    "    # Use train only to explore and for fitting\n",
    "    # Only use validate to validate models after fitting on train\n",
    "    # Only use test to test best model \n",
    "    return train, validate, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42b39c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validate, test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6a5f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735715",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4bec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(train, valid, test):\n",
    "    '''\n",
    "    Uses the train & test datasets created by the split_my_data function\n",
    "    Returns 3 items: mm_scaler, train_scaled_mm, test_scaled_mm\n",
    "    This is a linear transformation. Values will lie between 0 and 1\n",
    "    '''\n",
    "    num_vars = list(train.select_dtypes('number').columns)\n",
    "    scaler = MinMaxScaler(copy=True, feature_range=(0,1))\n",
    "    train[num_vars] = scaler.fit_transform(train[num_vars])\n",
    "    valid[num_vars] = scaler.transform(valid[num_vars])\n",
    "    test[num_vars] = scaler.transform(test[num_vars])\n",
    "    return scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9c28a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler, train_scaled, validate_scaled, test_scaled = min_max_scaler(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a48312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c258f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
